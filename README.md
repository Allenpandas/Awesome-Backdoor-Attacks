# Awesome-Backdoor-Attacks

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

> üòà/üòá A repository for documenting and exploring the <u>backdoor attacks</u>, featuring a curated collection of research groups, conferences, journals, competitions, papers, reports, and resource. Inspired by [awesome-php](https://github.com/ziadoz/awesome-php).



## Contributing

Please feel free to send me [issues](https://github.com/Allenpandas/Awesome-Backdoor-Attacks/issues) and [pull requests](https://github.com/Allenpandas/Awesome-Backdoor-Attacks/pulls) to add links.

**Markdown formatÔºö**

```
- **Paper Name.** [[pdf](link)] [[code](link)]
    - Author 1, Author 2, and Author 3. *venue, year.*
```

## Paper List

- [AAAI (20~25)](#AAAI) ‚úÖ
- [NeurIPS (18~24)](#NeurIPS) ‚úÖ NeruIPS'25 üîç
- [ICLR (20~25)](#ICLR) ‚úÖ
- [CVPR (20~25)](#CVPR) ‚úÖ
- TIFS
- [S&P (19~25)](#SP) ‚úÖ
- TDSC
- [UsenixSecurity (21~24)](#UsenixSecurity) ‚úÖ UsenixSecurity'25 üîç
- [ICML (21~24)](#ICML) ‚úÖ ICML'25 üîç
- [MM (21~24)](#ACM-MM) ‚úÖ ACM MM'25 üîç
- [ACL (21~25)](#ACL) ‚úÖ
- [IJCAI (21~24)](#IJCAI)  ‚úÖ IJCAI'25 üîç
- [ECCV (20~24)](#ECCV) ‚úÖ
- [NDSS (23~25)](#NDSS) ‚úÖ
- [CCS (19~24)](#CCS) ‚úÖ CCS'25 üîç
- [ICCV (21~23)](#ICCV) ‚úÖ ICCV'25 üîç

### Refine by Year

To be continued...

### Refine by venue

#### AAAI

- **Meme Trojan: Backdoor Attacks Against Hateful Meme Detection via Cross-Modal Triggers.** [[pdf](https://doi.org/10.1609/aaai.v39i8.32845)]
    - Ruofei Wang, Hongzhan Lin, Ziyuan Luo, Ka Chun Cheung, Simon See, Jing Ma, Renjie Wan. *AAAI 2025.*
- **HoneypotNet: Backdoor Attacks Against Model Extraction.** [[pdf](https://doi.org/10.1609/aaai.v39i8.32872)]
    - Yixu Wang, Tianle Gu, Yan Teng, Yingchun Wang, Xingjun Ma. *AAAI 2025.*
- **Attention-Imperceptible Backdoor Attacks on Vision Transformers.** [[pdf](https://doi.org/10.1609/aaai.v39i8.32889)]
    - Zhishen Wang, Rui Wang, Lihua Jing. *AAAI 2025.*
- **Backdoor Attacks Against No-Reference Image Quality Assessment Models via a Scalable Trigger.** [[pdf](https://doi.org/10.1609/aaai.v39i9.33051)]
    - Yi Yu, Song Xia, Xun Lin, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot. *AAAI 2025.*
- **SADBA: Self-Adaptive Distributed Backdoor Attack Against Federated Learning.** [[pdf](https://doi.org/10.1609/aaai.v39i16.33820)]
    - Jun Feng, Yuzhe Lai, Hong Sun, Bocheng Ren. *AAAI 2025.*
- **Backdoor Attack on Propagation-based Rumor Detectors.** [[pdf](https://doi.org/10.1609/aaai.v39i17.33944)]
    - Di Jin, Yujun Zhang, Bingdao Feng, Xiaobao Wang, Dongxiao He, Zhen Wang. *AAAI 2025.*
- **Attack on Prompt: Backdoor Attack in Prompt-Based Continual Learning.** [[pdf](https://doi.org/10.1609/aaai.v39i18.34168)]
    - Trang Nguyen, Anh Tran, Nhat Ho. *AAAI 2025.*
- **Label-Free Backdoor Attacks in Vertical Federated Learning.** [[pdf](https://doi.org/10.1609/aaai.v39i19.34246)]
    - Wei Shen, Wenke Huang, Guancheng Wan, Mang Ye. *AAAI 2025.*
- **Influence-Based Fair Selection for Sample-Discriminative Backdoor Attack.** [[pdf](https://doi.org/10.1609/aaai.v39i20.35449)]
    - Qi Wei, Shuo He, Jiahan Zhang, Lei Feng, Bo An. *AAAI 2025.*
- **Clean-Label Graph Backdoor Attack in the Node Classification Task.** [[pdf](https://doi.org/10.1609/aaai.v39i20.35466)]
    - Hui Xia, Xiangwei Zhao, Rui Zhang, Shuo Xu, Luming Wang. *AAAI 2025.*
- **Watch Out for Your Guidance on Generation! Exploring Conditional Backdoor Attacks against Large Language Models.** [[pdf](https://doi.org/10.1609/aaai.v39i25.34819)]
    - Jiaming He, Wenbo Jiang, Guanyu Hou, Wenshu Fan, Rui Zhang, Hongwei Li. *AAAI 2025.*
- **CL-Attack: Textual Backdoor Attacks via Cross-Lingual Triggers.** [[pdf](https://doi.org/10.1609/aaai.v39i25.34842)]
    - Jingyi Zheng, Tianyi Hu, Tianshuo Cong, Xinlei He. *AAAI 2025.*
- **IBAS: Imperceptible Backdoor Attacks in Split Learning with Limited Information.** [[pdf](https://doi.org/10.1609/aaai.v39i26.34986)]
    - Peng Xi, Shaoliang Peng, Wenjuan Tang. *AAAI 2025.*
- **A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives.** [[pdf](https://doi.org/10.1609/aaai.v38i3.27954)]
    - Yudong Gao, Honglong Chen, Peng Sun, Junjian Li, Anqing Zhang, Zhibo Wang, Weifeng Liu. *AAAI 2024.*
- **COMBAT: Alternated Training for Effective Clean-Label Backdoor Attacks.** [[pdf](https://doi.org/10.1609/aaai.v38i3.28019)]
    - Tran Huynh, Dang Nguyen, Tung Pham, Anh Tran. *AAAI 2024.*
- **Temporal-Distributed Backdoor Attack against Video Based Action Recognition.** [[pdf](https://doi.org/10.1609/aaai.v38i4.28104)]
    - Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis. *AAAI 2024.*
- **SEER: Backdoor Detection for Vision-Language Models through Searching Target Text and Image Trigger Jointly.** [[pdf](https://doi.org/10.1609/aaai.v38i7.28611)]
    - Liuwan Zhu, Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu. *AAAI 2024.*
- **BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning.** [[pdf](https://doi.org/10.1609/aaai.v38i10.29052)]
    - Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang. *AAAI 2024.*
- **Backdoor Adjustment via Group Adaptation for Debiased Coupon Recommendations.** [[pdf](https://doi.org/10.1609/aaai.v38i11.29081)]
    - Junpeng Fang, Gongduo Zhang, Qing Cui, Caizhi Tang, Lihong Gu, Longfei Li, Jinjie Gu, Jun Zhou. *AAAI 2024.*
- **Backdoor Attacks via Machine Unlearning.** [[pdf](https://doi.org/10.1609/aaai.v38i13.29321)]
    - Zihao Liu, Tianhao Wang, Mengdi Huai, Chenglin Miao. *AAAI 2024.*
- **Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective.** [[pdf](https://doi.org/10.1609/aaai.v38i13.29385)]
    - Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng. *AAAI 2024.*
- **Chronic Poisoning: Backdoor Attack against Split Learning.** [[pdf](https://doi.org/10.1609/aaai.v38i15.29591)]
    - Fangchao Yu, Bo Zeng, Kai Zhao, Zhi Pang, Lina Wang. *AAAI 2024.*
- **Conditional Backdoor Attack via JPEG Compression.** [[pdf](https://doi.org/10.1609/aaai.v38i18.29957)]
    - Qiuyu Duan, Zhongyun Hua, Qing Liao, Yushu Zhang, Leo Yu Zhang. *AAAI 2024.*
- **Does Few-Shot Learning Suffer from Backdoor Attacks?** [[pdf](https://doi.org/10.1609/aaai.v38i18.29965)]
    - Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao. *AAAI 2024.*
- **Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain.** [[pdf](https://doi.org/10.1609/aaai.v38i19.30099)]
    - Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li. *AAAI 2024.*
- **Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models.** [[pdf](https://doi.org/10.1609/aaai.v38i19.30110)]
    - Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Ming Hu, Tianlin Li, Geguang Pu, Yang Liu. *AAAI 2024.*
- **Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning.** [[pdf](https://doi.org/10.1609/aaai.v38i19.30131)]
    - Tao Liu, Yuhang Zhang, Zhu Feng, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang. *AAAI 2024.*
- **Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning.** [[pdf](https://doi.org/10.1609/aaai.v37i7.26083)]
    - Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Bin Wang, Jiqiang Liu, Xiangliang Zhang. *AAAI 2023.*
- **Poisoning-Based Backdoor Attacks in Computer Vision.** [[pdf](https://doi.org/10.1609/aaai.v37i13.26921)]
    - Yiming Li. *AAAI 2023.*
- **Backdoor Attacks on the DNN Interpretation System.** [[pdf](https://doi.org/10.1609/aaai.v36i1.19935)]
    - Shihong Fang, Anna Choromanska. *AAAI 2022.*
- **Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks.** [[pdf](https://doi.org/10.1609/aaai.v36i9.21191)]
    - Jinyuan Jia, Yupei Liu, Xiaoyu Cao, Neil Zhenqiang Gong. *AAAI 2022.*
- **Hibernated Backdoor: A Mutual Information Empowered Backdoor Attack to Deep Neural Networks.** [[pdf](https://doi.org/10.1609/aaai.v36i9.21272)]
    - Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu, Chonggang Wang. *AAAI 2022.*
- **DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation.** [[pdf](https://doi.org/10.1609/aaai.v35i12.17266)]
    - Zhicong Yan, Gaolei Li, Yuan Tian, Jun Wu, Shenghong Li, Mingzhe Chen, H. Vincent Poor. *AAAI 2021.*
- **Hidden Trigger Backdoor Attacks.** [[pdf](https://doi.org/10.1609/aaai.v34i07.6871)]
    - Aniruddha Saha, Akshayvarun Subramanya, Hamed Pirsiavash. *AAAI 2020.*

---

#### NeurIPS

- **Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/263c763d00c6126d37ba670a1fa10847-Abstract-Conference.html)]
    - Alkis Kalavasis, Amin Karbasi, Argyris Oikonomou, Katerina Sotiraki, Grigoris Velegkas, Manolis Zampetakis. *NeurIPS 2024.*
- **Data Free Backdoor Attacks.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/2a7e91c6e4b68325d9884a7469804837-Abstract-Conference.html)]
    - Bochuan Cao, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, Jinghui Chen, Bo Li, Dawn Song. *NeurIPS 2024.*
- **WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/4ce18228ececb78bca04cbce069891b1-Abstract-Conference.html)]
    - Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Yiyu Shi, Xian Wei, Mingsong Chen. *NeurIPS 2024.*
- **Everyday Object Meets Vision-and-Language Navigation Agent via Backdoor.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/58e6c003c9fb3992265005ff6aef1913-Abstract-Conference.html)]
    - Keji He, Kehan Chen, Jiawang Bai, Yan Huang, Qi Wu, Shu-Tao Xia, Liang Wang. *NeurIPS 2024.*
- **Unelicitable Backdoors via Cryptographic Transformer Circuits.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/6087a60306544be7ba0d0cf34aa93c8f-Abstract-Conference.html)]
    - Andis Draguns, Andrew Gritsevskiy, Sumeet Ramesh Motwani, Christian Schr√∂der de Witt. *NeurIPS 2024.*
- **Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/97d008f7873b8dd55cb6dd343fc4386f-Abstract-Conference.html)]
    - Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini. *NeurIPS 2024.*
- **Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html)]
    - Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun. *NeurIPS 2024.*
- **SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html)]
    - Ethan Rathbun, Christopher Amato, Alina Oprea. *NeurIPS 2024.*
- **BAN: Detecting Backdoors Activated by Adversarial Neuron Noise.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html)]
    - Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek. *NeurIPS 2024.*
- **BackTime: Backdoor Attacks on Multivariate Time Series Forecasting.** [[pdf](http://papers.nips.cc/paper_files/paper/2024/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html)]
    - Xiao Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong. *NeurIPS 2024.*
- **CBD: A Certified Backdoor Detector Based on Local Dominant Probability.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/0fbf046448d7eea18b982001320b9a10-Abstract-Conference.html)]
    - Zhen Xiang, Zidi Xiong, Bo Li. *NeurIPS 2023.*
- **Robust Contrastive Language-Image Pretraining against Data Poisoning and Backdoor Attacks.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/2232e8fee69b150005ac420bfa83d705-Abstract-Conference.html)]
    - Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman. *NeurIPS 2023.*
- **Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/677c8dc72c99482507323f313faf4738-Abstract-Conference.html)]
    - Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang. *NeurIPS 2023.*
- **VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html)]
    - Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho. *NeurIPS 2023.*
- **BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/802e90325f4c8546e13e5763b2ecab88-Abstract-Conference.html)]
    - Xuan Chen, Wenbo Guo, Guanhong Tao, Xiangyu Zhang, Dawn Song. *NeurIPS 2023.*
- **BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/828bb8f42d4ab15322b9315151959c61-Abstract-Conference.html)]
    - Bin Huang, Jiaqian Yu, Yiwei Chen, Siyang Pan, Qiang Wang, Zhi Wang. *NeurIPS 2023.*
- **A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/c07d71ff0bc042e4b9acd626a79597fa-Abstract-Conference.html)]
    - Hangfan Zhang, Jinyuan Jia, Jinghui Chen, Lu Lin, Dinghao Wu. *NeurIPS 2023.*
- **IBA: Towards Irreversible Backdoor Attacks in Federated Learning.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html)]
    - Thuy Dung Nguyen, Tuan Nguyen, Anh Tran, Khoa D. Doan, Kok-Seng Wong. *NeurIPS 2023.*
- **Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/e7938ede51225b490bb69f7b361a9259-Abstract-Conference.html)]
    - Ruixiang (Ryan) Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu. *NeurIPS 2023.*
- **Towards Stable Backdoor Purification through Feature Shift Tuning.** [[pdf](http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html)]
    - Rui Min, Zeyu Qin, Li Shen, Minhao Cheng. *NeurIPS 2023.*
- **Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/0799492e7be38b66d10ead5e8809616d-Abstract-Conference.html)]
    - Biru Zhu, Yujia Qin, Ganqu Cui, Yangyi Chen, Weilin Zhao, Chong Fu, Yangdong Deng, Zhiyuan Liu, Jingang Wang, Wei Wu, Maosong Sun, Ming Gu. *NeurIPS 2022.*
- **A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/2052b3e0617ecb2ce9474a6feaf422b3-Abstract-Datasets_and_Benchmarks.html)]
    - Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun. *NeurIPS 2022.*
- **Handcrafted Backdoors in Deep Neural Networks.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html)]
    - Sanghyun Hong, Nicholas Carlini, Alexey Kurakin. *NeurIPS 2022.*
- **BackdoorBench: A Comprehensive Benchmark of Backdoor Learning.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html)]
    - Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen. *NeurIPS 2022.*
- **Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/55bfedfd31489e5ae83c9ce8eec7b0e1-Abstract-Conference.html)]
    - Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li. *NeurIPS 2022.*
- **Pre-activation Distributions Expose Backdoor Neurons.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/76917808731dae9e6d62c2a7a6afb542-Abstract-Conference.html)]
    - Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu. *NeurIPS 2022.*
- **Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/79eec295a3cd5785e18c61383e7c996b-Abstract-Conference.html)]
    - Hossein Souri, Liam Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein. *NeurIPS 2022.*
- **Finding Naturally Occurring Physical Backdoors in Image Datasets.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/8af749935131cc8ea5dae4f6d8cdb304-Abstract-Datasets_and_Benchmarks.html)]
    - Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Heather Zheng, Ben Y. Zhao. *NeurIPS 2022.*
- **One-shot Neural Backdoor Erasing via Adversarial Weight Masking.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/8c0f7107ab85892ccf51f0a814957af1-Abstract-Conference.html)]
    - Shuwen Chai, Jinghui Chen. *NeurIPS 2022.*
- **Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/db1d5c63576587fc1d40d33a75190c71-Abstract-Conference.html)]
    - Ruisi Cai, Zhenyu Zhang, Tianlong Chen, Xiaohan Chen, Zhangyang Wang. *NeurIPS 2022.*
- **Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/ea06e6e9e80f1c3d382317fff67041ac-Abstract-Conference.html)]
    - Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang. *NeurIPS 2022.*
- **BadPrompt: Backdoor Attacks on Continuous Prompts.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/f0722b58f02d7793acf7d328928f933a-Abstract-Conference.html)]
    - Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, Xiaojie Yuan. *NeurIPS 2022.*
- **Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class.** [[pdf](http://papers.nips.cc/paper_files/paper/2022/hash/fa0126bb7ebad258bf4ffdbbac2dd787-Abstract-Conference.html)]
    - Khoa D. Doan, Yingjie Lao, Ping Li. *NeurIPS 2022.*
- **Anti-Backdoor Learning: Training Clean Models on Poisoned Data.** [[pdf](https://proceedings.neurips.cc/paper/2021/hash/7d38b1e9bd793d3f45e0e212a729a93c-Abstract.html)]
   - Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma. *NeurIPS 2021.*
- **Adversarial Neuron Pruning Purifies Backdoored Deep Models.** [[pdf](https://proceedings.neurips.cc/paper/2021/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html)]
   - Dongxian Wu, Yisen Wang. *NeurIPS 2021.*
- **Backdoor Attack with Imperceptible Input and Latent Modification.** [[pdf](https://proceedings.neurips.cc/paper/2021/hash/9d99197e2ebf03fc388d09f1e94af89b-Abstract.html)]
   - Khoa D. Doan, Yingjie Lao, Ping Li. *NeurIPS 2021.*
- **Excess Capacity and Backdoor Poisoning.** [[pdf](https://proceedings.neurips.cc/paper/2021/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html)]
   - Naren Manoj, Avrim Blum. *NeurIPS 2021.*
- **Input-Aware Dynamic Backdoor Attack.** [[pdf](https://proceedings.neurips.cc/paper/2020/hash/234e691320c0ad5b45ee3c96d0d7b8f8-Abstract.html)]
    - Tuan Anh Nguyen, Anh Tuan Tran. *NeurIPS 2020.*
- **On the Trade-off between Adversarial and Backdoor Robustness.** [[pdf](https://proceedings.neurips.cc/paper/2020/hash/8b4066554730ddfaa0266346bdc1b202-Abstract.html)]
    - Cheng-Hsin Weng, Yan-Ting Lee, Shan-Hung Wu. *NeurIPS 2020.*
- **Attack of the Tails: Yes, You Really Can Backdoor Federated Learning.** [[pdf](https://proceedings.neurips.cc/paper/2020/hash/b8ffa41d4e492f0fad2f13e29e1762eb-Abstract.html)]
    - Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris S. Papailiopoulos. *NeurIPS 2020.*
- **Defending Neural Backdoors via Generative Distribution Modeling.** [[pdf](https://proceedings.neurips.cc/paper/2019/hash/78211247db84d96acf4e00092a7fba80-Abstract.html)]
    - Ximing Qiao, Yukun Yang, Hai Li. *NeurIPS 2019.*
- **Spectral Signatures in Backdoor Attacks.** [[pdf](https://proceedings.neurips.cc/paper/2018/hash/280cf18baf4311c92aa5a042336587d3-Abstract.html)]
    - Brandon Tran, Jerry Li, Aleksander Madry. *NeurIPS 2018.*

#### ICLR

- **BadJudge: Backdoor Vulnerabilities of LLM-As-A-Judge.** [[pdf](https://openreview.net/forum?id=eC2a2IndIt)]
    - Terry Tong, Fei Wang, Zhe Zhao, Muhao Chen. *ICLR 2025.*
- **Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems.** [[pdf](https://openreview.net/forum?id=S1Bv3068Xt)]
    - Ruochen Jiao, Shaoyuan Xie, Justin Yue, Takami Sato, Lixu Wang, Yixuan Wang, Qi Alfred Chen, Qi Zhu. *ICLR 2025.*
- **Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks.** [[pdf](https://openreview.net/forum?id=1Z3C49JQVf)]
    - Nguyen Hung-Quang, Ngoc-Hieu Nguyen, The-Anh Ta, Thanh Nguyen-Tang, Kok-Seng Wong, Hoang Thanh-Tung, Khoa D. Doan. *ICLR 2025.*
- **Injecting Universal Jailbreak Backdoors into LLMs in Minutes.** [[pdf](https://openreview.net/forum?id=aSy2nYwiZ2)]
    - Zhuowei Chen, Qiannan Zhang, Shichao Pei. *ICLR 2025.*
- **Backdooring Vision-Language Models with Out-Of-Distribution Data.** [[pdf](https://openreview.net/forum?id=tZozeR3VV7)]
    - Weimin Lyu, Jiachen Yao, Saumya Gupta, Lu Pang, Tao Sun, Lingjie Yi, Lijie Hu, Haibin Ling, Chao Chen. *ICLR 2025.*
- **Bad-PFL: Exploiting Backdoor Attacks against Personalized Federated Learning.** [[pdf](https://openreview.net/forum?id=79nO2DPjVX)]
    - Mingyuan Fan, Zhanyi Hu, Fuyi Wang, Cen Chen. *ICLR 2025.*
- **Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection.** [[pdf](https://openreview.net/forum?id=8iTpB4RNvP)]
    - Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao. *ICLR 2024.*
- **Influencer Backdoor Attack on Semantic Segmentation.** [[pdf](https://openreview.net/forum?id=VmGRoNDQgJ)]
    - Haoheng Lan, Jindong Gu, Philip Torr, Hengshuang Zhao. *ICLR 2024.*
- **Demystifying Poisoning Backdoor Attacks from a Statistical Perspective.** [[pdf](https://openreview.net/forum?id=BPHcEpGvF8)]
    - Ganghua Wang, Xun Xian, Ashish Kundu, Jayanth Srinivasa, Xuan Bi, Mingyi Hong, Jie Ding. *ICLR 2024.*
- **BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models.** [[pdf](https://openreview.net/forum?id=c93SBwz1Ma)]
    - Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li. *ICLR 2024.*
- **Backdoor Contrastive Learning via Bi-level Trigger Optimization.** [[pdf](https://openreview.net/forum?id=oxjeePpgSP)]
    - Weiyu Sun, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, Jinghui Chen, Lu Lin. *ICLR 2024.*
- **Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective.** [[pdf](https://openreview.net/forum?id=iCNOK45Csv)]
    - Ming-Yu Chung, Sheng-Yen Chou, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo, Tsung-Yi Ho. *ICLR 2024.*
- **BadEdit: Backdooring Large Language Models by Model Editing.** [[pdf](https://openreview.net/forum?id=duZANm2ABX)]
    - Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, Yang Liu. *ICLR 2024.*
- **Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark.** [[pdf](https://openreview.net/forum?id=cObFETcoeW)]
    - Mengxi Ya, Yiming Li, Tao Dai, Bin Wang, Yong Jiang, Shu-Tao Xia. *ICLR 2024.*
- **Universal Backdoor Attacks.** [[pdf](https://openreview.net/forum?id=3QkzYBSWqL)]
    - Benjamin Schneider, Nils Lukas, Florian Kerschbaum. *ICLR 2024.*
- **Backdoor Federated Learning by Poisoning Backdoor-Critical Layers.** [[pdf](https://openreview.net/forum?id=AJBGSVSTT2)]
    - Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan. *ICLR 2024.*
- **Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios.** [[pdf](https://openreview.net/forum?id=vRyp2dhEQp)]
    - Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li. *ICLR 2024.*
- **Universal Jailbreak Backdoors from Poisoned Human Feedback.** [[pdf](https://openreview.net/forum?id=GxCGsxiAaK)]
    - Javier Rando, Florian Tram√®r. *ICLR 2024.*
- **Rethinking CNN's Generalization to Backdoor Attack from Frequency Domain.** [[pdf](https://openreview.net/forum?id=mYhH0CDFFa)]
    - Quanrui Rao, Lin Wang, Wuying Liu. *ICLR 2024.*
- **Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only.** [[pdf](https://openreview.net/forum?id=rFQfjDC9Mt)]
    - Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li, Tianwei Zhang. *ICLR 2023.*
- **FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning.** [[pdf](https://openreview.net/forum?id=Xo2E217_M4n)]
    - Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang. *ICLR 2023.*
- **Few-shot Backdoor Attacks via Neural Tangent Kernels.** [[pdf](https://openreview.net/forum?id=a70lGJ-rwy)]
    - Jonathan Hayase, Sewoong Oh. *ICLR 2023.*
- **Revisiting the Assumption of Latent Separability for Backdoor Defenses.** [[pdf](https://openreview.net/forum?id=_wSHsgrVali)]
    - Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal. *ICLR 2023.*
- **The Dark Side of AutoML: Towards Architectural Backdoor Search.** [[pdf](https://openreview.net/forum?id=bsZULlDGXe)]
    - Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang. *ICLR 2023.*
- **Poisoning and Backdooring Contrastive Learning.** [[pdf](https://openreview.net/forum?id=iC4UHbQ01Mp)]
  - Nicholas Carlini, Andreas Terzis. *ICLR 2022.*
- **BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models.** [[pdf](https://openreview.net/forum?id=Mng8CQ9eBW)]
  - Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, Chun Fan. *ICLR 2022.*
- **Adversarial Unlearning of Backdoors via Implicit Hypergradient.** [[pdf](https://openreview.net/forum?id=MeeQkFYVbzW)]
  - Yi Zeng, Si Chen, Won Park, Zhuoqing Mao, Ming Jin, Ruoxi Jia. *ICLR 2022.*
- **Few-Shot Backdoor Attacks on Visual Object Tracking.** [[pdf](https://openreview.net/forum?id=qSV5CuSaK_a)]
  - Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia. *ICLR 2022.*
- **How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data.** [[pdf](https://openreview.net/forum?id=Bn09TnDngN)]
  - Zhiyuan Zhang, Lingjuan Lyu, Weiqiang Wang, Lichao Sun, Xu Sun. *ICLR 2022.
- **WaNet - Imperceptible Warping-based Backdoor Attack.** [[pdf](https://openreview.net/forum?id=eEn8KTtJOx)]
    - Tuan Anh Nguyen, Anh Tuan Tran. *ICLR 2021.*
- **DBA: Distributed Backdoor Attacks against Federated Learning.** [[pdf](https://openreview.net/forum?id=rkgyS0VFvr)]
    - Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li. *ICLR 2020.*

---

#### CVPR

- **Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.html)]
    - Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Mingli Zhu, Xiaochun Cao, Dacheng Tao. *CVPR 2025.*
- **UIBDiffusion: Universal Imperceptible Backdoor Attack for Diffusion Models.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Han_UIBDiffusion_Universal_Imperceptible_Backdoor_Attack_for_Diffusion_Models_CVPR_2025_paper.html)]
    - Yuning Han, Bingyin Zhao, Rui Chu, Feng Luo, Biplab Sikdar, Yingjie Lao. *CVPR 2025.*
- **Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Stealthy_Backdoor_Attack_in_Self-Supervised_Learning_Vision_Encoders_for_Large_CVPR_2025_paper.html)]
    - Zhaoyi Liu, Huan Zhang. *CVPR 2025.*
- **Infighting in the Dark: Multi-Label Backdoor Attack in Federated Learning.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Li_Infighting_in_the_Dark_Multi-Label_Backdoor_Attack_in_Federated_Learning_CVPR_2025_paper.html)]
    - Ye Li, Yanchao Zhao, Chengcheng Zhu, Jiale Zhang. *CVPR 2025.*
- **Invisible Backdoor Attack against Self-supervised Learning.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.html)]
    - Hanrong Zhang, Zhenting Wang, Boheng Li, Fulin Lin, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma. *CVPR 2025.*
- **BadToken: Token-level Backdoor Attacks to Multi-modal Large Language Models.** [[pdf](https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_BadToken_Token-level_Backdoor_Attacks_to_Multi-modal_Large_Language_Models_CVPR_2025_paper.html)]
    - Zenghui Yuan, Jiawen Shi, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun. *CVPR 2025.*
- **Physical Backdoor: Towards Temperature-Based Backdoor Attacks in the Physical World.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.01210)]
    - Wen Yin, Jian Lou, Pan Zhou, Yulai Xie, Dan Feng, Yuhua Sun, Tailai Zhang, Lichao Sun. *CVPR 2024.*
- **Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.01410)]
    - Mozhgan Pourkeshavarz, Mohammad Sabokrou, Amir Rasouli. *CVPR 2024.*
- **BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.02288)]
    - Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu. *CVPR 2024.*
- **Data Poisoning Based Backdoor Attacks to Contrastive Learning.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.02299)]
    - Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong. *CVPR 2024.*
- **Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transfomers.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.02306)]
    - Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-Tao Xia. *CVPR 2024.*
- **BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.02327)]
    - Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, Ee-Chien Chang. *CVPR 2024.*
- **Lotus: Evasive and Resilient Backdoor Attacks through Sub-Partitioning.** [[pdf](https://doi.org/10.1109/CVPR52733.2024.02342)]
    - Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang. *CVPR 2024.*
- **How to Backdoor Diffusion Models?** [[pdf](https://doi.org/10.1109/CVPR52729.2023.00391)]
    - Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho. *CVPR 2023.*
- **Color Backdoor: A Robust Poisoning Attack in Color Space.** [[pdf](https://doi.org/10.1109/CVPR52729.2023.00786)]
    - Wenbo Jiang, Hongwei Li, Guowen Xu, Tianwei Zhang. *CVPR 2023.*
- **Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger.** [[pdf](https://doi.org/10.1109/CVPR52729.2023.01179)]
    - Yi Yu, Yufei Wang, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot. *CVPR 2023.*
- **The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection.** [[pdf](https://doi.org/10.1109/CVPR52729.2023.02355)]
    - Simin Chen, Hanlin Chen, Mirazul Haque, Cong Liu, Wei Yang. *CVPR 2023.*
- **Architectural Backdoors in Neural Networks.** [[pdf](https://doi.org/10.1109/CVPR52729.2023.02356)]
    - Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot. *CVPR 2023.*
- **You Are Catching My Attention: Are Vision Transformers Bad Learners under Backdoor Attacks?** [[pdf](https://doi.org/10.1109/CVPR52729.2023.02357)]
    - Zenghui Yuan, Pan Zhou, Kai Zou, Yu Cheng. *CVPR 2023.*
- **Backdoor Attacks on Self-Supervised Learning.** [[pdf](https://doi.org/10.1109/CVPR52688.2022.01298)]
    - Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash. *CVPR 2022.*
- **Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks.** [[pdf](https://doi.org/10.1109/CVPR52688.2022.01299)]
    - Xiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, Kai Bu. *CVPR 2022.*
- **DEFEAT: Deep Hidden Feature Backdoor Attacks by Imperceptible Perturbation and Latent Representation Constraints.** [[pdf](https://doi.org/10.1109/CVPR52688.2022.01478)]
    - Zhendong Zhao, Xiaojun Chen, Yuexin Xuan, Ye Dong, Dakui Wang, Kaitai Liang. *CVPR 2022.*
- **Dual-Key Multimodal Backdoors for Visual Question Answering.** [[pdf](https://doi.org/10.1109/CVPR52688.2022.01494)]
    - Matthew Walmer, Karan Sikka, Indranil Sur, Abhinav Shrivastava, Susmit Jha. *CVPR 2022.*
- **FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis.** [[pdf](https://doi.org/10.1109/CVPR52688.2022.02021)]
    - Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao. *CVPR 2022.*
- **Backdoor Attacks Against Deep Learning Systems in the Physical World.** [[pdf](https://openaccess.thecvf.com/content/CVPR2021/html/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.html)]
    - Emily Wenger, Josephine Passananti, Arjun Nitin Bhagoji, Yuanshun Yao, Haitao Zheng, Ben Y. Zhao. *CVPR 2021.*
- **Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs.** [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/html/Kolouri_Universal_Litmus_Patterns_Revealing_Backdoor_Attacks_in_CNNs_CVPR_2020_paper.html)]
    - Soheil Kolouri, Aniruddha Saha, Hamed Pirsiavash, Heiko Hoffmann. *CVPR 2020.*
- **Clean-Label Backdoor Attacks on Video Recognition Models.** [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/html/Zhao_Clean-Label_Backdoor_Attacks_on_Video_Recognition_Models_CVPR_2020_paper.html)]
    - Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey, Jingjing Chen, Yu-Gang Jiang. *CVPR 2020.*

---

#### S&P

- **Secure Transfer Learning: Training Clean Model Against Backdoor in Pre-Trained Encoder and Downstream Dataset.** [[pdf](https://doi.org/10.1109/SP61157.2025.00162)]
    - Yechao Zhang, Yuxuan Zhou, Tianyu Li, Minghui Li, Shengshan Hu, Wei Luo, Leo Yu Zhang. *S&P 2025.*
- **Architectural Neural Backdoors from First Principles.** [[pdf](https://doi.org/10.1109/SP61157.2025.00060)]
    - Harry Langford, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot. *S&P 2025.*
- **BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target.** [[pdf](https://doi.org/10.1109/SP61157.2025.00103)]
    - Guangyu Shen, Siyuan Cheng, Zhuo Zhang, Guanhong Tao, Kaiyuan Zhang, Hanxi Guo, Lu Yan, Xiaolong Jin, Shengwei An, Shiqing Ma, Xiangyu Zhang. *S&P 2025.*
- **PEFTGuard: Detecting Backdoor Attacks Against Parameter-Efficient Fine-Tuning.** [[pdf](https://doi.org/10.1109/SP61157.2025.00161)]
    - Zhen Sun, Tianshuo Cong, Yule Liu, Chenhao Lin, Xinlei He, Rongmao Chen, Xingshuo Han, Xinyi Huang. *S&P 2025.*
- **Need for Speed: Taming Backdoor Attacks with Speed and Precision.** [[pdf](https://doi.org/10.1109/SP54263.2024.00216)]
    - Zhuo Ma, Yilong Yang, Yang Liu, Tong Yang, Xinjing Liu, Teng Li, Zhan Qin. *S&P 2024.*
- **FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge.** [[pdf](https://doi.org/10.1109/SP54263.2024.00148)]
    - Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan, Elisa Bertino. *S&P 2024.*
- **OdScan: Backdoor Scanning for Object Detection Models.** [[pdf](https://doi.org/10.1109/SP54263.2024.00119)]
    - Siyuan Cheng, Guangyu Shen, Guanhong Tao, Kaiyuan Zhang, Zhuo Zhang, Shengwei An, Xiangzhe Xu, Yingqi Li, Shiqing Ma, Xiangyu Zhang. *S&P 2024.*
- **MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.** [[pdf](https://doi.org/10.1109/SP54263.2024.00015)]
    - Hang Wang, Zhen Xiang, David J. Miller, George Kesidis. *S&P 2024.*
- **BadVFL: Backdoor Attacks in Vertical Federated Learning.** [[pdf](https://doi.org/10.1109/SP54263.2024.00008)]
    - Mohammad Naseri, Yufei Han, Emiliano De Cristofaro. *S&P 2024.*
- **Distribution Preserving Backdoor Attack in Self-supervised Learning.** [[pdf](https://doi.org/10.1109/SP54263.2024.00029)]
    - Guanhong Tao, Zhenting Wang, Shiwei Feng, Guangyu Shen, Shiqing Ma, Xiangyu Zhang. *S&P 2024.*
- **Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics.** [[pdf](https://doi.org/10.1109/SP54263.2024.00174)]
    - Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang. *S&P 2024.*
- **DeepVenom: Persistent DNN Backdoors Exploiting Transient Weight Perturbations in Memories.** [[pdf](https://doi.org/10.1109/SP54263.2024.00223)]
    - Kunbei Cai, Md Hafizul Islam Chowdhuryy, Zhenkai Zhang, Fan Yao. *S&P 2024.*
- **Baffle: Hiding Backdoors in Offline Reinforcement Learning Datasets.** [[pdf](https://doi.org/10.1109/SP54263.2024.00224)]
    - Chen Gong, Zhou Yang, Yunpeng Bai, Junda He, Jieke Shi, Kecen Li, Arunesh Sinha, Bowen Xu, Xinwen Hou, David Lo, Tianhao Wang. *S&P 2024.*
- **Exploring the Orthogonality and Linearity of Backdoor Attacks.** [[pdf](https://doi.org/10.1109/SP54263.2024.00225)]
    - Kaiyuan Zhang, Siyuan Cheng, Guangyu Shen, Guanhong Tao, Shengwei An, Anuran Makur, Shiqing Ma, Xiangyu Zhang. *S&P 2024.*
- **BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.** [[pdf](https://doi.org/10.1109/SP54263.2024.00226)]
    - Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang. *S&P 2024.*
- **Backdooring Multimodal Learning.** [[pdf](https://doi.org/10.1109/SP54263.2024.00031)]
    - Xingshuo Han, Yutong Wu, Qingjie Zhang, Yuan Zhou, Yuan Xu, Han Qiu, Guowen Xu, Tianwei Zhang. *S&P 2024.*
- **Disguising Attacks with Explanation-Aware Backdoors.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179308)]
    - Maximilian Noppel, Lukas Peter, Christian Wressnegger. *S&P 2023.*
- **AI-Guardian: Defeating Adversarial Attacks using Backdoors.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179473)]
    - Hong Zhu, Shengzhi Zhang, Kai Chen. *S&P 2023.*
- **Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179347)]
    - Limin Yang, Zhi Chen, Jacopo Cortellazzi, Feargus Pendlebury, Kevin Tu, Fabio Pierazzi, Lorenzo Cavallaro, Gang Wang. *S&P 2023.*
- **Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179375)]
    - Xueluan Gong, Yanjiao Chen, Wang Yang, Qian Wang, Yuzhe Gu, Huayang Huang, Chao Shen. *S&P 2023.*
- **RAB: Provable Robustness Against Backdoor Attacks.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179451)]
    - Maurice Weber, Xiaojun Xu, Bojan Karlas, Ce Zhang, Bo Li. *S&P 2023.*
- **3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179401)]
    - Haoyang Li, Qingqing Ye, Haibo Hu, Jin Li, Leixia Wang, Chengfang Fang, Jie Shi. *S&P 2023.*
- **MagBackdoor: Beware of Your Loudspeaker as A Backdoor For Magnetic Injection Attacks.** [[pdf](https://doi.org/10.1109/SP46215.2023.10179364)]
    - Tiantian Liu, Feng Lin, Zhangsen Wang, Chao Wang, Zhongjie Ba, Li Lu, Wenyao Xu, Kui Ren. *S&P 2023.*
- **Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models.** [[pdf](https://doi.org/10.1109/SP46215.2023.10351028)]
    - Rui Zhu, Di Tang, Siyuan Tang, Xiaofeng Wang, Haixu Tang. *S&P 2023.*
- **Piccolo: Exposing Complex Backdoors in NLP Transformer Models.** [[pdf](https://doi.org/10.1109/SP46214.2022.9833579)]
    - Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, Shiqing Ma, Xiangyu Zhang. *S&P 2022.*
- **BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning.** [[pdf](https://doi.org/10.1109/SP46214.2022.9833644)]
    - Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong. *S&P 2022.*
- **True2F: Backdoor-Resistant Authentication Tokens.** [[pdf](https://doi.org/10.1109/SP.2019.00048)]
    - Emma Dauterman, Henry Corrigan-Gibbs, David Mazi√®res, Dan Boneh, Dominic Rizzo. *S&P 2019.*

---

#### UsenixSecurity

- **An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/yan)]
    - Shenao Yan, Shen Wang, Yue Duan, Hanbin Hong, Kiho Lee, Doowon Kim, Yuan Hong. *Usenix Security 2024.*
- **Instruction Backdoor Attacks Against Customized LLMs.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-rui)]
    - Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang. *Usenix Security 2024.*
- **On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/li-changjiang)]
    - Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang. *Usenix Security 2024.*
- **Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/liu-hongbin)]
    - Hongbin Liu, Michael K. Reiter, Neil Zhenqiang Gong. *Usenix Security 2024.*
- **Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/lyu)]
    - Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Yongsheng Zhu, Guangquan Xu, Jiqiang Liu, Xiangliang Zhang. *Usenix Security 2024.*
- **UBA-Inf: Unlearning Activated Backdoor Attack with Influence-Driven Camouflage.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/huang-zirui)]
    - Zirui Huang, Yunlong Mao, Sheng Zhong. *Usenix Security 2024.*
- **Devil in the Room: Triggering Audio Backdoors in the Physical World.** [[pdf](https://www.usenix.org/conference/usenixsecurity24/presentation/chen-meng)]
    - Meng Chen, Xiangyu Xu, Li Lu, Zhongjie Ba, Feng Lin, Kui Ren. *Usenix Security 2024.*
- **PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis.** [[pdf](https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-pelican)]
    - Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu, Yapeng Ye, Yaoxuan Wu, Xiangyu Zhang. *Usenix Security 2023.*
- **A Data-free Backdoor Injection Approach in Neural Networks.** [[pdf](https://www.usenix.org/conference/usenixsecurity23/presentation/lv)]
    - Peizhuo Lv, Chang Yue, Ruigang Liang, Yunfei Yang, Shengzhi Zhang, Hualong Ma, Kai Chen. *Usenix Security 2023.*
- **Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks.** [[pdf](https://www.usenix.org/conference/usenixsecurity23/presentation/tian)]
    - Jianwen Tian, Kefan Qiu, Debin Gao, Zhi Wang, Xiaohui Kuang, Gang Zhao. *Usenix Security 2023.*
- **Aliasing Backdoor Attacks on Pre-trained Models.** [[pdf](https://www.usenix.org/conference/usenixsecurity23/presentation/wei-chengan)]
    - Cheng'an Wei, Yeonjoon Lee, Kai Chen, Guozhu Meng, Peizhuo Lv. *Usenix Security 2023.*
- **VILLAIN: Backdoor Attacks Against Vertical Split Learning.** [[pdf](https://www.usenix.org/conference/usenixsecurity23/presentation/bai)]
    - Yijie Bai, Yanjiao Chen, Hanlei Zhang, Wenyuan Xu, Haiqin Weng, Dou Goodman. *Usenix Security 2023.*
- **Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.** [[pdf](https://www.usenix.org/conference/usenixsecurity22/presentation/pan-hidden)]
    - Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, Min Yang. *Usenix Security 2022.*
- **Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers.** [[pdf](https://www.usenix.org/conference/usenixsecurity21/presentation/severi)]
    - Giorgio Severi, Jim Meyer, Scott E. Coull, Alina Oprea. *Usenix Security 2021.*
- **Blind Backdoors in Deep Learning Models.** [[pdf](https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan)]
    - Eugene Bagdasaryan, Vitaly Shmatikov. *Usenix Security 2021.*
- **Graph Backdoor.** [[pdf](https://www.usenix.org/conference/usenixsecurity21/presentation/xi)]
    - Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang. *Usenix Security 2021.*

---

#### ICML

- **The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright BreachesWithout Adjusting Finetuning Pipeline.** [[pdf](https://openreview.net/forum?id=ZvFLbEPv6x)]
    - Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, Kenji Kawaguchi. *ICML 2024.*
- **A Theoretical Analysis of Backdoor Poisoning Attacks in Convolutional Neural Networks.** [[pdf](https://openreview.net/forum?id=SfcB4cVvPz)]
    - Boqi Li, Weiwei Liu. *ICML 2024.*
- **Privacy Backdoors: Stealing Data with Corrupted Pretrained Models.** [[pdf](https://openreview.net/forum?id=7yixJXmzb8)]
    - Shanglun Feng, Florian Tram√®r. *ICML 2024.*
- **Generalization Bound and New Algorithm for Clean-Label Backdoor Attack.** [[pdf](https://openreview.net/forum?id=ZdqiT0McON)]
    - Lijia Yu, Shuang Liu, Yibo Miao, Xiao-Shan Gao, Lijun Zhang. *ICML 2024.*
- **Chameleon: Adapting to Peer Images for Planting Durable Backdoors in Federated Learning.** [[pdf](https://proceedings.mlr.press/v202/dai23a.html)]
    - Yanbo Dai, Songze Li. *ICML 2023.*
- **Rethinking Backdoor Attacks.** [[pdf](https://proceedings.mlr.press/v202/khaddaj23a.html)]
    - Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry. *ICML 2023.*
- **Understanding Backdoor Attacks through the Adaptability Hypothesis.** [[pdf](https://proceedings.mlr.press/v202/xian23a.html)]
    - Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding. *ICML 2023.*
- **UMD: Unsupervised Model Detection for X2X Backdoor Attacks.** [[pdf](https://proceedings.mlr.press/v202/xiang23a.html)]
    - Zhen Xiang, Zidi Xiong, Bo Li. *ICML 2023.*
- **Graph Contrastive Backdoor Attacks.** [[pdf](https://proceedings.mlr.press/v202/zhang23e.html)]
    - Hangfan Zhang, Jinghui Chen, Lu Lin, Jinyuan Jia, Dinghao Wu. *ICML 2023.*
- **Neurotoxin: Durable Backdoors in Federated Learning.** [[pdf](https://proceedings.mlr.press/v162/zhang22w.html)]
    - Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Prateek Mittal, Kannan Ramchandran, Joseph Gonzalez. *ICML 2022.*
- **Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks.** [[pdf](http://proceedings.mlr.press/v139/schwarzschild21a.html)]
    - Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P. Dickerson, Tom Goldstein. *ICML 2021.*

---

#### ACM MM

- **EvilEdit: Backdooring Text-to-Image Diffusion Models in One Second.** [[pdf](https://doi.org/10.1145/3664647.3680689)]
    - Hao Wang, Shangwei Guo, Jialing He, Kangjie Chen, Shudong Zhang, Tianwei Zhang, Tao Xiang. *ACM MM 2024.*
- **Backdoor Attacks on Bimodal Salient Object Detection with RGB-Thermal Data.** [[pdf](https://doi.org/10.1145/3664647.3681096)]
    - Wen Yin, Bin Benjamin Zhu, Yulai Xie, Pan Zhou, Dan Feng. *ACM MM 2024.*
- **Towards Robust Physical-world Backdoor Attacks on Lane Detection.** [[pdf](https://doi.org/10.1145/3664647.3680766)]
    - Xinwei Zhang, Aishan Liu, Tianyuan Zhang, Siyuan Liang, Xianglong Liu. *ACM MM 2024.*
- **Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning.** [[pdf](https://doi.org/10.1145/3581783.3612108)]
    - Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su. *ACM MM 2023.*
- **Physical Invisible Backdoor Based on Camera Imaging.** [[pdf](https://doi.org/10.1145/3581783.3612476)]
    - Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang. *ACM MM 2023.*
- **The Silent Manipulator: A Practical and Inaudible Backdoor Attack against Speech Recognition Systems.** [[pdf](https://doi.org/10.1145/3581783.3613843)]
    - Zhicong Zheng, Xinfeng Li, Chen Yan, Xiaoyu Ji, Wenyuan Xu. *ACM MM 2023.*
- **Moir√© Backdoor Attack (MBA): A Novel Trigger for Pedestrian Detectors in the Physical World.** [[pdf](https://doi.org/10.1145/3581783.3611910)]
    - Hui Wei, Hanxun Yu, Kewei Zhang, Zhixiang Wang, Jianke Zhu, Zheng Wang. *ACM MM 2023.*
- **PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification.** [[pdf](https://doi.org/10.1145/3581783.3612032)]
    - Yizhen Yuan, Rui Kong, Shenghao Xie, Yuanchun Li, Yunxin Liu. *ACM MM 2023.*
- **BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label.** [[pdf](https://doi.org/10.1145/3503161.3548272)]
    - Shengshan Hu, Ziqi Zhou, Yechao Zhang, Leo Yu Zhang, Yifeng Zheng, Yuanyuan He, Hai Jin. *ACM MM 2022.*
- **Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems.** [[pdf](https://doi.org/10.1145/3503161.3548261)]
    - Qiang Liu, Tongqing Zhou, Zhiping Cai, Yonghao Tang. *ACM MM 2022.*
- **Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving.** [[pdf](https://doi.org/10.1145/3503161.3548171)]
    - Xingshuo Han, Guowen Xu, Yuan Zhou, Xuehuan Yang, Jiwei Li, Tianwei Zhang. *ACM MM 2022.*
- **Backdoor Attacks on Crowd Counting.** [[pdf](https://doi.org/10.1145/3503161.3548296)]
    - Yuhua Sun, Tailai Zhang, Xingjun Ma, Pan Zhou, Jian Lou, Zichuan Xu, Xing Di, Yu Cheng, Lichao Sun. *ACM MM 2022.*
- **Anti-Distillation Backdoor Attacks: Backdoors Can Really Survive in Knowledge Distillation.** [[pdf](https://doi.org/10.1145/3474085.3475254)]
  - Yunjie Ge, Qian Wang, Baolin Zheng, Xinlu Zhuang, Qi Li, Chao Shen, Cong Wang. *ACM MM 2021.*

---

#### ACL

- **When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations.** [[pdf](https://aclanthology.org/2025.acl-long.114/)]
    - Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang. *ACL 2025.*
- **BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents.** [[pdf](https://doi.org/10.18653/v1/2024.acl-long.530)]
  - Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian. *ACL 2024.*
- **A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning.** [[pdf](https://doi.org/10.18653/v1/2023.acl-long.194)]
    - Naibin Gu, Peng Fu, Xiyu Liu, Zhengxiao Liu, Zheng Lin, Weiping Wang. *ACL 2023.*
- **Multi-target Backdoor Attacks for Code Pre-trained Models.** [[pdf](https://doi.org/10.18653/v1/2023.acl-long.399)]
    - Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, Yang Liu. *ACL 2023.*
- **Backdooring Neural Code Search.** [[pdf](https://doi.org/10.18653/v1/2023.acl-long.540)]
    - Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang, Quanjun Zhang, Bin Luo. *ACL 2023.*
- **BITE: Textual Backdoor Attacks with Iterative Trigger Injection.** [[pdf](https://doi.org/10.18653/v1/2023.acl-long.725)]
    - Jun Yan, Vansh Gupta, Xiang Ren. *ACL 2023.*
- **NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models.** [[pdf](https://doi.org/10.18653/v1/2023.acl-long.867)]
    - Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma. *ACL 2023.*
- **Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger.** [[pdf](https://doi.org/10.18653/v1/2021.acl-long.37)]
    - Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun. *ACL 2021.*
- **Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution.** [[pdf](https://doi.org/10.18653/v1/2021.acl-long.377)]
    - Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun. *ACL 2021.*
- **Rethinking Stealthiness of Backdoor Attack against NLP Models.** [[pdf](https://doi.org/10.18653/v1/2021.acl-long.431)]
    - Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun. *ACL 2021.*

---

#### IJCAI

- **BadFusion: 2D-Oriented Backdoor Attacks against 3D Object Detection.** [[pdf](https://www.ijcai.org/proceedings/2024/39)]
  - Saket S. Chaturvedi, Lan Zhang, Wenbin Zhang, Pan He, Xiaoyong Yuan. *IJCAI 2024.*
- **BADFSS: Backdoor Attacks on Federated Self-Supervised Learning.** [[pdf](https://www.ijcai.org/proceedings/2024/61)]
  - Jiale Zhang, Chengcheng Zhu, Di Wu, Xiaobing Sun, Jianming Yong, Guodong Long. *IJCAI 2024.*
- **Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control.** [[pdf](https://www.ijcai.org/proceedings/2024/78)]
  - Ka-Ho Chow, Wenqi Wei, Lei Yu. *IJCAI 2024.*
- **DarkFed: A Data-Free Backdoor Attack in Federated Learning.** [[pdf](https://www.ijcai.org/proceedings/2024/491)]
  - Minghui Li, Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Leo Yu Zhang, Yichen Wang. *IJCAI 2024.*

- **PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning.** [[pdf](https://doi.org/10.24963/ijcai.2022/96)]
    - Wei Du, Yichun Zhao, Boqun Li, Gongshen Liu, Shilin Wang. *IJCAI 2022.*
- **Imperceptible Backdoor Attack: From Input Space to Feature Representation.** [[pdf](https://doi.org/10.24963/ijcai.2022/242)]
    - Nan Zhong, Zhenxing Qian, Xinpeng Zhang. *IJCAI 2022.*
- **Membership Inference via Backdooring.** [[pdf](https://doi.org/10.24963/ijcai.2022/532)]
    - Hongsheng Hu, Zoran Salcic, Gillian Dobbie, Jinjun Chen, Lichao Sun, Xuyun Zhang. *IJCAI 2022.*
- **Data-Efficient Backdoor Attacks.** [[pdf](https://doi.org/10.24963/ijcai.2022/554)]
    - Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li. *IJCAI 2022.*

- **Backdoor DNFs.** [[pdf](https://doi.org/10.24963/ijcai.2021/194)]
    - Sebastian Ordyniak, Andr√© Schidler, Stefan Szeider. *IJCAI 2021.*
- **BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning.** [[pdf](https://doi.org/10.24963/ijcai.2021/509)]
    - Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song. *IJCAI 2021.*

---

#### ECCV

- **WBP: Training-Time Backdoor Attacks Through Hardware-Based Weight Bit Poisoning.** [[pdf](https://doi.org/10.1007/978-3-031-73650-6_11)]
  - Kunbei Cai, Zhenkai Zhang3460, Qian Lou, Fan Yao. *ECCV 2024*
- **Data Poisoning Quantization Backdoor Attack.** [[pdf](https://doi.org/10.1007/978-3-031-72907-2_3)]
  - Tran Huynh, Anh Tran, Khoa D. Doan, Tung Pham. *ECCV 2024*
- **TrojVLM: Backdoor Attack Against Vision Language Models.** [[pdf](https://doi.org/10.1007/978-3-031-73650-6_27)]
  - Weimin Lyu, Lu Pang, Tengfei Ma, Haibin Ling, Chao Chen. *ECCV 2024*
- **Flatness-Aware Sequential Learning Generates Resilient Backdoors.** [[pdf](https://doi.org/10.1007/978-3-031-73021-4_6)]
  - Hoang Pham, The-Anh Ta,  Anh Tran, Khoa D. Doan. *ECCV 2024.*
- **Event Trojan: Asynchronous Event-Based Backdoor Attacks.** [[pdf](https://doi.org/10.1007/978-3-031-72667-5_18)]
  - Ruofei Wang, Qing Guo, Haoliang Li, Renjie Wan. *ECCV 2024.*
- **Towards Physical World Backdoor Attacks Against Skeleton Action Recognition.** [[pdf](https://doi.org/10.1007/978-3-031-73195-2_13)]
  - Qichen Zheng, Yi Yu, Siyuan Yang, Jun Liu, Kwok-Yan Lam, Alex ChiChung Kot. *ECCV 2024.*
- **RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN.** [[pdf](https://doi.org/10.1007/978-3-031-19772-7_41)]
  - Huy Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan. *ECCV 2022.*
- **An Invisible Black-Box Backdoor Attack Through Frequency Domain.** [[pdf](https://doi.org/10.1007/978-3-031-19778-9_23)]
  - Tong Wang, Yuan Yao, Feng Xu, Shengwei An, Hanghang Tong, Ting Wang. *ECCV 2022.*
- **Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks.** [[pdf](https://doi.org/10.1007/978-3-030-58607-2_11)]
  - Yunfei Liu, Xingjun Ma, James Bailey, Feng Lu. *ECCV 2020.*

---

#### NDSS

- **LADDER: Multi-Objective Backdoor Attack via Evolutionary Algorithm.** [[pdf](https://www.ndss-symposium.org/ndss-paper/ladder-multi-objective-backdoor-attack-via-evolutionary-algorithm/)]
  - Dazhuang Liu, Yanqi Qiao, Rui Wang, Kaitai Liang, Georgios Smaragdakis. *NDSS 2025.*
- **Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering.** [[pdf](https://www.ndss-symposium.org/ndss-paper/gradient-shaping-enhancing-backdoor-attack-against-reverse-engineering/)]
  - Rui Zhu, Di Tang, Siyuan Tang, Zihao Wang, Guanhong Tao, Shiqing Ma, XiaoFeng Wang, Haixu Tang. *NDSS 2024.*
- **Backdoor Attacks Against Dataset Distillation.** [[pdf](https://www.ndss-symposium.org/ndss-paper/backdoor-attacks-against-dataset-distillation/)]
  - Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang. *NDSS 2023.*

---

#### CCS

- **Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses.** [[pdf](https://doi.org/10.1145/3658644.3690187)]
  - Yuxin Yang, Qiang Li, Jinyuan Jia, Yuan Hong, Binghui Wang. *CCS 2024.*
- **BadMerging: Backdoor Attacks Against Model Merging.** [[pdf](https://doi.org/10.1145/3658644.3690284)]
  - Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian. *CCS 2024.*
- **Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense.** [[pdf](https://doi.org/10.1145/3658644.3670361)]
  - Hua Ma, Shang Wang, Yansong Gao, Zhi Zhang, Huming Qiu, Minhui Xue, Alsharif Abuadbba, Anmin Fu, Surya Nepal, Derek Abbott. *CCS 2024.*
- **Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information.** [[pdf](https://doi.org/10.1145/3576915.3616617)]
    - Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia. *CCS 2023.*
- **Hidden Backdoors in Human-Centric Language Models.** [[pdf](https://doi.org/10.1145/3460120.3484576)]
    - Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu. *CCS 2021.*
- **Backdoor Pre-trained Models Can Transfer to All.** [[pdf](https://doi.org/10.1145/3460120.3485370)]
    - Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang. *CCS 2021.*
- **Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign Features.** [[pdf](https://doi.org/10.1145/3372297.3423362)]
    - Junyu Lin, Lei Xu, Yingqi Liu, Xiangyu Zhang. *CCS 2020.*
- **Latent Backdoor Attacks on Deep Neural Networks.** [[pdf](https://doi.org/10.1145/3319535.3354209)]
    - Yuanshun Yao, Huiying Li, Haitao Zheng, Ben Y. Zhao. *CCS 2019.*

---

#### ICCV

- **An Embarrassingly Simple Backdoor Attack on Self-supervised Learning.** [[pdf](https://doi.org/10.1109/ICCV51070.2023.00403)]
    - Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang. *ICCV 2023.*
- **Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis.** [[pdf](https://doi.org/10.1109/ICCV51070.2023.00423)]
    - Lukas Struppek, Dominik Hintersdorf, Kristian Kersting. *ICCV 2023.*
- **The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning.** [[pdf](https://doi.org/10.1109/ICCV51070.2023.00436)]
    - Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr. *ICCV 2023.*
- **Computation and Data Efficient Backdoor Attacks.** [[pdf](https://doi.org/10.1109/ICCV51070.2023.00443)]
    - Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang. *ICCV 2023.*
- **A Backdoor Attack against 3D Point Cloud Classifiers.** [[pdf](https://doi.org/10.1109/ICCV48922.2021.00750)]
    - Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis. *ICCV 2021.*
- **LIRA: Learnable, Imperceptible and Robust Backdoor Attacks.** [[pdf](https://doi.org/10.1109/ICCV48922.2021.01175)]
    - Khoa D. Doan, Yingjie Lao, Weijie Zhao, Ping Li. *ICCV 2021.*
- **Invisible Backdoor Attack with Sample-Specific Triggers.** [[pdf](https://doi.org/10.1109/ICCV48922.2021.01615)]
    - Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu. *ICCV 2021.*
- **Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective.** [[pdf](https://doi.org/10.1109/ICCV48922.2021.01616)]
    - Yi Zeng, Won Park, Z. Morley Mao, Ruoxi Jia. *ICCV 2021.*
- **PointBA: Towards Backdoor Attacks in 3D Point Cloud.** [[pdf](https://doi.org/10.1109/ICCV48922.2021.01618)]
    - Xinke Li, Zhirui Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim, Joey Tianyi Zhou. *ICCV 2021.*
